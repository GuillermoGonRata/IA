{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82ec77e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82ec77e2",
        "outputId": "32e67d70-3d03-4a9e-effa-cee19f4ed939"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"GPU disponible:\", tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3X_6Eheyd30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3X_6Eheyd30",
        "outputId": "81cf6a22-5209-4613-af08-e852f5530613"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Tamaño y batch\n",
        "img_size = (48, 48)\n",
        "batch_size = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Ruta del dataset\n",
        "dataDir = \"dataset/train\"\n",
        "\n",
        "# Carga de datos\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    dataDir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=img_size,\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "original_train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    dataDir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=img_size,\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Clases\n",
        "class_names = original_train_ds.class_names\n",
        "\n",
        "# Normalización\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "\n",
        "# Data augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomContrast(0.2),\n",
        "])\n",
        "\n",
        "# Pipeline optimizado\n",
        "train_ds = original_train_ds.cache().shuffle(1000).map(\n",
        "    lambda x, y: (data_augmentation(normalization_layer(x), training=True), y),\n",
        "    num_parallel_calls=AUTOTUNE\n",
        ").prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "val_ds = val_ds.cache().map(\n",
        "    lambda x, y: (normalization_layer(x), y),\n",
        "    num_parallel_calls=AUTOTUNE\n",
        ").prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Verifica GPU\n",
        "print(\"Dispositivos GPU disponibles:\", tf.config.list_physical_devices('GPU'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db70f5e0",
      "metadata": {
        "id": "db70f5e0"
      },
      "source": [
        "## Entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b61eab4e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b61eab4e",
        "outputId": "1a3e1d4c-1180-437b-b92d-51df23eee707"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "train_ds = train_ds.map(lambda x, y: (data_augmentation(x,training=True), y))\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomContrast(0.2),\n",
        "])\n",
        "\n",
        "model = models.Sequential([\n",
        "    keras.layers.Input(shape=(48, 48, 1)),\n",
        "\n",
        "    keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    keras.layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    keras.layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    keras.layers.GlobalAveragePooling2D(),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(len(class_names), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint(\"best_model.h5\", save_best_only=True)\n",
        "\n",
        "\n",
        "y_train = []\n",
        "for _, labels in train_ds.unbatch():\n",
        "    y_train.append(labels.numpy())\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# Callback para detener entrenamiento si no mejora\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=6,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Callback para guardar el mejor modelo\n",
        "checkpoint = ModelCheckpoint(\n",
        "    \"best_model.h5\",          # nombre del archivo\n",
        "    monitor='val_loss',       # métrica a vigilar\n",
        "    save_best_only=True,      # solo guarda si mejora\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Entrenamiento con callbacks\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=30,\n",
        "    callbacks=[early_stop, checkpoint],  # aquí incluyes ambos\n",
        "    class_weight=class_weights_dict\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WJ2rb0AG3i_r",
      "metadata": {
        "id": "WJ2rb0AG3i_r"
      },
      "source": [
        "## Descargar el modelo:\n",
        "ya que lo estaba haciendo directamente desde google colab, con esto descargo el modelo de la pagina."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "5Ks08q2c3iDz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "5Ks08q2c3iDz",
        "outputId": "2526b2d7-95d8-4ba0-aa6c-182145a815b6"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_29b15ce1-6bc9-447e-9d12-d6d1dcd0fd60\", \"best_model.h5\", 14689736)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"best_model.h5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8efeb6fd",
      "metadata": {
        "id": "8efeb6fd"
      },
      "source": [
        "## Matriz de confusion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d5f0c73f",
      "metadata": {
        "id": "d5f0c73f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step\n",
            "[[397  93  22  62 233  52]\n",
            " [180 171   9  61 190 199]\n",
            " [187  41 894  94 106  86]\n",
            " [ 58  89  57 472 312  53]\n",
            " [170 123  29 133 486  37]\n",
            " [ 24  55  13  16  12 525]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.39      0.46      0.42       859\n",
            "        fear       0.30      0.21      0.25       810\n",
            "       happy       0.87      0.63      0.74      1408\n",
            "     neutral       0.56      0.45      0.50      1041\n",
            "         sad       0.36      0.50      0.42       978\n",
            "    surprise       0.55      0.81      0.66       645\n",
            "\n",
            "    accuracy                           0.51      5741\n",
            "   macro avg       0.51      0.51      0.50      5741\n",
            "weighted avg       0.54      0.51      0.52      5741\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Predicciones\n",
        "y_pred = np.argmax(model.predict(val_ds), axis=1)\n",
        "\n",
        "# Etiquetas verdaderas\n",
        "y_true = []\n",
        "for _, labels in val_ds.unbatch():\n",
        "    y_true.append(labels.numpy())\n",
        "y_true = np.array(y_true)\n",
        "\n",
        "# Reporte\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "79b0d897",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "79b0d897",
        "outputId": "36167a83-8391-4c62-dd7d-6ed27408940c"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'seaborn'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
          ]
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9822b60a",
      "metadata": {
        "id": "9822b60a"
      },
      "source": [
        "## Evaluacion del accuaracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c8ca952",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c8ca952",
        "outputId": "42dbd50b-fe9d-47b4-a16b-9e1bbb4616ea"
      },
      "outputs": [],
      "source": [
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"dataset/test\",\n",
        "    image_size=img_size,\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y)).cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(f\"Test accuracy: {test_acc:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fff4e4f",
      "metadata": {
        "id": "6fff4e4f"
      },
      "source": [
        "## Grafica para ver la accuaracy del modelo:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d6f4163",
      "metadata": {
        "id": "6d6f4163"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Train Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Val Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Train Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Val Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0394fa03",
      "metadata": {
        "id": "0394fa03"
      },
      "source": [
        "## Guardar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e70c81a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e70c81a",
        "outputId": "4104af35-3ebc-41fa-c0e1-807ebd337cab"
      },
      "outputs": [],
      "source": [
        "model.save(\"emotion_model.h5\")\n",
        "# model.save(\"emotion_model.keras\") <-- Esta forma la recomienda keras ya que el que usamos se ve mas antiguo, pero ocupo confirmar con la documentación"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
